<!DOCTYPE html>

<html lang="en">
<head>
<title>Web VR boilerplate</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<style>
body {
  width: 100%;
  height: 100%;
  background-color: #000;
  color: #fff;
  margin: 0px;
  padding: 0;
  overflow: hidden;
}
</style>
</head>

<body>

</body>

<script>
/*
 * Debug parameters.
 */

// Forces availability of VR mode.
//CARDBOARD_DEBUG = true;
// Forces distortion in VR mode.
//WEBVR_FORCE_DISTORTION = true;
// Override the distortion background color.
//WEBVR_BACKGROUND_COLOR = {x: 1, y: 0, z: 0, w: 1};
// Change the tracking prediction mode.
//WEBVR_PREDICTION_MODE = 2;
// In prediction mode, change how far into the future to predict.
//WEBVR_PREDICTION_TIME_MS = 100;
</script>

<!--
  three.js 3d library
  -->
<script src="bower_components/threejs/build/three.js"></script>

<!--
  VRControls.js acquires positional information from connected VR devices and applies the transformations to a three.js camera object.
   -->
<script src="bower_components/threejs/examples/js/controls/VRControls.js"></script>

<!--
  VREffect.js handles stereo camera setup and rendering.
  -->
<script src="bower_components/threejs/examples/js/effects/VREffect.js"></script>

<!--
  A polyfill for WebVR using the Device{Motion,Orientation}Event API.
  -->
<script src="bower_components/webvr-polyfill/build/webvr-polyfill.js"></script>

<!--
  Helps enter and exit VR mode, provides best practices while in VR.
  -->
<script src="build/webvr-manager.js"></script>


<script>
//Setup three.js WebGL renderer
var renderer = new THREE.WebGLRenderer({ antialias: true });
renderer.setPixelRatio(window.devicePixelRatio);

// Append the canvas element created by the renderer to document body element.
document.body.appendChild(renderer.domElement);

// Create a three.js scene.
var scene = new THREE.Scene();

// Create a three.js camera.
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);

// Apply VR headset positional data to camera.
var controls = new THREE.VRControls(camera);

// Apply VR stereo rendering to renderer.
var effect = new THREE.VREffect(renderer);
effect.setSize(window.innerWidth, window.innerHeight);

//create a sphere - we'll use the inner surface to project our image on to it
var geometry  = new THREE.SphereGeometry(50, 200, 200)
var lightgeometry  = new THREE.SphereGeometry(48, 200, 200)

// create the material, using a texture of mars
var material  = new THREE.MeshBasicMaterial();
material.map   = THREE.ImageUtils.loadTexture('img/beiji.jpg');
material.side  = THREE.BackSide;

//极光贴图
var lightmaterial  = new THREE.MeshBasicMaterial();
lightmaterial.map   = THREE.ImageUtils.loadTexture('img/light.png');
lightmaterial.side  = THREE.BackSide;
lightmaterial.transparent = true;
lightmaterial.opacity = 0.6;

var lightflag = true;
function lighttime(timestamp){
  //var curopac = lightmaterial.opacity;
    /*if(lightmaterial.opacity >= 0.7){
      lightmaterial.opacity -= 0.02;
    }else if(lightmaterial.opacity <= 0.3){
      lightmaterial.opacity += 0.02;
    }else{
      if(Math.random() > 0.5){
        lightmaterial.opacity += 0.02;
      }else{
        lightmaterial.opacity -= 0.02;
      }
    }*/
    if(lightmaterial.opacity >= 0.7){
      lightflag = false;
      //lightmaterial.opacity = 0.2;
    }
    else if(lightmaterial.opacity <= 0.2){
      lightflag = true;
      //lightmaterial.opacity += 0.005;
    }
    if(lightflag == true){
      lightmaterial.opacity += 0.005;
    }else{
      lightmaterial.opacity -= 0.005;
    }
    controls.update();

    // Render the scene through the manager.
    manager.render(scene, camera, timestamp);

    requestAnimationFrame(lighttime);
}

// create the mesh based on geometry and material
var mesh  = new THREE.Mesh(geometry, material);
var skybox = new THREE.Mesh(geometry, material);
scene.add(skybox);  

//将极光图层贴至场景中
var lightmesh  = new THREE.Mesh(lightgeometry, lightmaterial);
var lightskybox = new THREE.Mesh(lightgeometry, lightmaterial);
scene.add(lightskybox);

//lighttime();


// Create a VR manager helper to enter and exit VR mode.
var manager = new WebVRManager(renderer, effect, {hideButton: false});

// Create 3D objects.
var geometry = new THREE.SphereGeometry(0.5, 32, 32);
var material = new THREE.MeshBasicMaterial();
var earthMesh = new THREE.Mesh(geometry, material);

// Position earth mesh
earthMesh.position.z = 10;
earthMesh.position.x = 15;
earthMesh.position.y = 2;


// Add earth mesh to your three.js scene
scene.add(earthMesh);

material.map = THREE.ImageUtils.loadTexture('img/earthmap1k.jpg')


// Add earthMesh mesh to your three.js scene
scene.add(earthMesh);
// Request animation frame loop function
function animate(timestamp) {
  // Apply rotation to earthMesh mesh
  earthMesh.rotation.y += 0.01;

  // Update VR headset position and apply to camera.
  controls.update();

  // Render the scene through the manager.
  manager.render(scene, camera, timestamp);

  requestAnimationFrame(animate);
}

// Kick off animation loop
animate();

lighttime();

// Reset the position sensor when 'z' pressed.
function onKey(event) {
  if (event.keyCode == 90) { // z
    controls.resetSensor();
  }
}

window.addEventListener('keydown', onKey, true);

// Handle window resizes
function onWindowResize() {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();

  effect.setSize(window.innerWidth, window.innerHeight);
}

window.addEventListener('resize', onWindowResize, false);

</script>

</html>
